# ğŸ§ Shahzam â€” Tiny Shazam clone in JavaScript

ğŸš€ A playful experiment to understand how Shazam-like music recognition works by building it yourself.  
ğŸ¯ No machine learning, just clever DSP (Digital Signal Processing) & inverted index search.

---

## ğŸ— Tech Highlights
âœ… Fully built in JavaScript (Node.js + Express + Meyda + plain HTML/JS frontend)  
âœ… Single monorepo, no microservices â€” just `/backend` & `/frontend` folders  
âœ… Uses JSON (`db.json`) as a tiny DB â€” **no external DB setup needed**  
âœ… Runs locally on your laptop, listens to your microphone live.

---

## âš™ï¸ How it works
1. ğŸ¤ Click **Start Listening** in your browser.  
2. ğŸ”¥ Meyda (running in browser) captures tiny audio slices (512 samples) from your mic, does FFT to get frequency spectrum.  
3. ğŸ“ˆ Finds the loudest frequency in each slice, builds **peaks over time**.  
4. ğŸ§¬ Forms pairs of peaks â†’ creates **unique hashes**.  
5. ğŸš€ Sends these hashes to your backend via POST `/match`.  
6. ğŸ—„ Backend looks up hashes in `db.json` (pre-generated fingerprints of songs).  
7. ğŸµ Returns the best match (or "No match found").  
8. ğŸ¥³ Displays song name in your browser.

---

## ğŸ£ v1 Scope
âœ… Live microphone listening  
âœ… Generates hashes in browser using Meyda  
âœ… Looks up hashes in local JSON DB  
âœ… Detects simple 3 songs  
âœ… No ML, no GPU needed

## ğŸš€ v2 (future ideas)
ğŸš€ Better peak pairing & time offset clustering (closer to Shazam paper)  
ğŸµ Store more songs (optimize with hashed database / trie)  
ğŸ“Š Visualize confidence level (bar graph, not just yes/no)  
ğŸŒ Deploy on server with upload endpoint for short clips  
ğŸ§ Add fallback: let user upload audio file if mic fails

---

## ğŸš€ Running locally

### â¬‡ï¸ Install dependencies
From your project root:
```bash
cd backend
npm install

Start backend
node index.js
(Backend will run on localhost:3001)

Start frontend
cd frontend
python3 -m http.server 8080
(or use npx serve / live-server / http-server.)
http://localhost:8080


DB:::
{
  "45-47-23": ["Mad About You"],
  "12-14-4": ["Mad About You"],
  "31-33-5": ["Lean On"],
  "56-58-15": ["Lean On"],
  "8-10-12": ["I Took A Pill In Ibiza"]
}


â¤ï¸ Why this is cool
âœ… Learn how real-world systems like Shazam work under the hood
âœ… No need for deep learning â€” see how clever math & inverted indexes can solve it
âœ… Build your own music recognition pipeline â€” DSP, fingerprints, DB lookup


